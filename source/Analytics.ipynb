{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/speaker_recognition_light/.venv/lib/python3.10/site-packages/s3prl/upstream/byol_s/byol_a/common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "/home/patrick/speaker_recognition_light/.venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "/home/patrick/speaker_recognition_light/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/patrick/speaker_recognition_light/.venv/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WavLM_Base_ECAPA_TDNN(\n",
       "  (frontend): UpstreamExpert(\n",
       "    (model): WavLM(\n",
       "      (feature_extractor): ConvFeatureExtractionModel(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "            (3): GELU(approximate='none')\n",
       "          )\n",
       "          (1-4): 4 x Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU(approximate='none')\n",
       "          )\n",
       "          (5-6): 2 x Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "      (dropout_features): Dropout(p=0.1, inplace=False)\n",
       "      (encoder): TransformerEncoder(\n",
       "        (pos_conv): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (1): SamePad()\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "              (relative_attention_bias): Embedding(320, 12)\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1-11): 11 x TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): Dropout(p=0.1, inplace=False)\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (embedding): ECAPA_TDNN(\n",
       "    (blocks): ModuleList(\n",
       "      (0): TDNNBlock(\n",
       "        (conv): Conv1d(\n",
       "          (conv): Conv1d(768, 512, kernel_size=(5,), stride=(1,))\n",
       "        )\n",
       "        (activation): ReLU()\n",
       "        (norm): BatchNorm1d(\n",
       "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SERes2NetBlock(\n",
       "        (tdnn1): TDNNBlock(\n",
       "          (conv): Conv1d(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (norm): BatchNorm1d(\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (res2net_block): Res2NetBlock(\n",
       "          (blocks): ModuleList(\n",
       "            (0-6): 7 x TDNNBlock(\n",
       "              (conv): Conv1d(\n",
       "                (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(2,))\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "              (norm): BatchNorm1d(\n",
       "                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (tdnn2): TDNNBlock(\n",
       "          (conv): Conv1d(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (norm): BatchNorm1d(\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (se_block): SEBlock(\n",
       "          (conv1): Conv1d(\n",
       "            (conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv1d(\n",
       "            (conv): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SERes2NetBlock(\n",
       "        (tdnn1): TDNNBlock(\n",
       "          (conv): Conv1d(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (norm): BatchNorm1d(\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (res2net_block): Res2NetBlock(\n",
       "          (blocks): ModuleList(\n",
       "            (0-6): 7 x TDNNBlock(\n",
       "              (conv): Conv1d(\n",
       "                (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(3,))\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "              (norm): BatchNorm1d(\n",
       "                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (tdnn2): TDNNBlock(\n",
       "          (conv): Conv1d(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (norm): BatchNorm1d(\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (se_block): SEBlock(\n",
       "          (conv1): Conv1d(\n",
       "            (conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv1d(\n",
       "            (conv): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SERes2NetBlock(\n",
       "        (tdnn1): TDNNBlock(\n",
       "          (conv): Conv1d(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (norm): BatchNorm1d(\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (res2net_block): Res2NetBlock(\n",
       "          (blocks): ModuleList(\n",
       "            (0-6): 7 x TDNNBlock(\n",
       "              (conv): Conv1d(\n",
       "                (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(4,))\n",
       "              )\n",
       "              (activation): ReLU()\n",
       "              (norm): BatchNorm1d(\n",
       "                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (tdnn2): TDNNBlock(\n",
       "          (conv): Conv1d(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (norm): BatchNorm1d(\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (se_block): SEBlock(\n",
       "          (conv1): Conv1d(\n",
       "            (conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv1d(\n",
       "            (conv): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mfa): TDNNBlock(\n",
       "      (conv): Conv1d(\n",
       "        (conv): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "      (norm): BatchNorm1d(\n",
       "        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (asp): AttentiveStatisticsPooling(\n",
       "      (tdnn): TDNNBlock(\n",
       "        (conv): Conv1d(\n",
       "          (conv): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (activation): ReLU()\n",
       "        (norm): BatchNorm1d(\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (tanh): Tanh()\n",
       "      (conv): Conv1d(\n",
       "        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (asp_bn): BatchNorm1d(\n",
       "      (norm): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Conv1d(\n",
       "      (conv): Conv1d(3072, 192, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from frontend import MFCCTransform\n",
    "from utils import get_device\n",
    "from speechbrain.lobes.models.ECAPA_TDNN import ECAPA_TDNN\n",
    "from models import WavLM_Base_ECAPA_TDNN\n",
    "\n",
    "MFCCS = 80\n",
    "EMBEDDING_SIZE = 192\n",
    "MODEL = \"WavLM-Base-joint_ECAPA-TDNN_Random-Triplet-Mining_Genuine\"\n",
    "\n",
    "device = get_device()\n",
    "#model = ECAPA_TDNN(input_size=MFCCS, lin_neurons=EMBEDDING_SIZE, device=device)\n",
    "frozen = False\n",
    "model = WavLM_Base_ECAPA_TDNN(frozen=frozen, device=device)\n",
    "model.to(device)\n",
    "\n",
    "state = torch.load(\n",
    "    f'../models/{MODEL}_best_model_state.pth')\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!Unknown: labels_BSI_train_genuine.txt\n",
      "number of deepfakes: 688432\n",
      "number of genuine: 8883\n"
     ]
    }
   ],
   "source": [
    "from utils import load_deepfake_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import ValidationDataset, collate_valid_fn\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "DOWNSAMPLING_VALID = -1\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_labels, dev_labels, test_labels = load_deepfake_dataset()\n",
    "\n",
    "#frontend = MFCCTransform(\n",
    "#    number_output_parameters=MFCCS, sample_rate=SAMPLE_RATE)\n",
    "frontend = lambda x: x\n",
    "\n",
    "validation_dataset = ValidationDataset(\n",
    "    train_labels, frontend=frontend, downsampling=DOWNSAMPLING_VALID)\n",
    "validation_dataset.data_list = validation_dataset.data_list[validation_dataset.data_list[\"is_genuine\"] == 1]\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                    drop_last=True, num_workers=4, pin_memory=True, collate_fn=collate_valid_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ModelValidator\n",
    "\n",
    "validator = ModelValidator(validation_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/555 [00:00<?, ?it/s]/home/patrick/speaker_recognition_light/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/patrick/speaker_recognition_light/.venv/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Generating embeddings: 100%|██████████| 555/555 [05:38<00:00,  1.64it/s]\n",
      "Computing pairwise scores: 39422760it [18:44, 35042.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8557785147430912,\n",
       " 0.8886529,\n",
       " {'TP': 0, 'TN': 39366846, 'FP': 0, 'FN': 55914},\n",
       " -1,\n",
       " -1,\n",
       " {})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.validate_model(model, deepfake_eer=False, mlflow_logging=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
